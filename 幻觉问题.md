[LLM幻觉](https://s19nzhlbmzc.feishu.cn/docx/OGHEdCs5YotY89xrNcbcygWHnXb#share-YAxdd2ARBoluPlxVNeMcWJF2nLB)

## 什么是幻觉？

大抵可以分为两类：事实性幻觉和诚实性幻觉

1. **事实不一致(Factual Inconsistency)，**包括事实不一致（与现实世界事实矛盾）和事实捏造（捏造不存在的事实）。
2. **忠实度幻觉(Faithfulness Hallucination)** ，模型无法跟随用户指令，模型输出与上下文不符，COT中逻辑存在内部矛盾。

**事实性幻觉可以通过RAG缓解，而用RAG又会遇见忠实度幻觉。**

## 幻觉的来源是什么？

1. 预训练中噪声数据(偏差、错误或过时的信息).
2. STF使模型倾向于尽量给出回答, 模型无法认知到自己的知识边界, 当问题超出模型认知时, 就可能导致幻觉
3. SFT时使用的数据格式为<instruction,input,output>，如果output中蕴含的知识是预训练阶段没有包括的，那么实际上在诱导模型做幻觉生成！
4. 解码策略, 解码时采样的采样算法本身就有随机性, 而且出现幻觉后, 模型又倾向于自圆其说而不是修正错误.
5. 模型太小, 无法记忆足够的知识，从而引发幻觉

## 如何检验幻觉？

https://www.aizws.net/news/detail/514

1. LogProbability，幻觉产生时，生成的回答会不够置信，低概率代表发生了幻觉
2. G-Eval，**告诉大模型检验标准，让大模型检验。**首先，他们向LLM提供任务介绍和评估标准，并要求其生成一个评估步骤的CoT。然后，为了评估摘要的质量，他们将提示、CoT、文章和摘要连接起来，并要求LLM输出一个1到5之间的分数。然后，他们使用LLM输出“1”、“2”等标记的概率来产生加权平均评分。当概率不可用时，作者从LLM中随机抽取20次，并对样本中的评分进行平均，以标准化分数，并将其加权求和作为最终结果。
3. 自检GPT：**通过多次采样输出**。如果一个LLM了解了一个给定的概念，那么采样的回答很可能是相似且一致的。然而，如果这个概念是虚构的，高温采样得到的回答很可能是相异且相互矛盾的。

## 如何缓解幻觉?

### RAG

1. 检索部分: 有用性?

2. 生成部分:

   1. **生成前检索.** Self-RAG, **motivation**：不管是否真的需要，传统的RAG都会无差别地访问知识库获取上下文补充信息，这样有可能会引入主题无关，甚至冲突的上下文，进而降低文本生成内容的质量。**核心idea**：在生成过程中引入`reflection token`（4种反思标记 ），来判断模型在回答query中要不要检索内容，判断检索内容是否相关，以及检索内容的支撑回答的程度怎样等问题.

       **生成前检索存在进入噪音的问题, 比较依赖检索器的效果.**

   2. **生成后检索.** FAVA, 简单说就是模型生成response后, 用一个Edit模型, 根据检索内容对response进行幻觉的检测与纠正, 论文中预先定义了6种幻觉. 

      **生成后检测的一个潜在问题是, 模型出现的幻觉超出了预先定义种类, 存在无法检测与纠正的问题.**

   3. **生成中检索.**  DRAGIN**,** 通过logits和熵判断是否产出了幻觉, 然后中断生成, 通过检索补充信息, 再生成.

      > LLM生成阶段检测LLM对生成token的不确定程度（包含每个token的不确定性，语义贡献和对后续上下文的影响），高于阈值触发检索然后构造new query（选择output tokens里面更相关的的token）去检索然后续写（ensuring the query reflects the most relevant aspects of the context as determined by the LLM’s self-attention mechanism.）

<img src="C:\Users\junji\Documents\BaiduSyncdisk\找工作\基础知识\assets\幻觉问题.assets\1724903595401-1.png" alt="img" style="zoom: 50%;" />

### Chain-of-Verification (CoVe)

 step 1 生成基线响应 （BASELINE RESPONSE）

 正常的LLM生成。生成的响应可能存在幻觉。

 step 2 规划验证（PLAN VERIFICATIONS）

 在原始查询和基线响应的基础上，模型生成一系列验证问题，测试响应中包含的事实性声明。

 例如，基线响应的一部分包含“[美墨战争](https://zhida.zhihu.com/search?q=美墨战争)是美国和墨西哥之间的武装冲突，从1846年到1848年”，那么一个可能的验证问题（用来检查日期准确性）是：“美墨战争何时开始和结束？”。

 step 3 执行验证（EXECUTE VERIFICATIONS）

### 个人想法

首先需要做一个验证实验，看看熵与幻觉的关系。比如有一个测试集，统计出现幻觉的样本中的熵与没出现幻觉样本的熵的比值。

 回退, 通过logits检测到幻觉后, 尝试回退到几个token之前重新生成. 

 理论上, 随着生成的进行, 模型应该越来越确定接下来该说什么, 是一个熵减的过程, 需要能量. 

 虽然随着推理的进行, 长度越来越长, 模型生成下一个token需要消耗的算力(能量)也就越来越多。这一点与物理规律相符。

> **低温下的物质状态变化**：例如，在非常低的温度下使系统接近绝对零度，此时的熵已经非常低，进一步降低温度（熵）所需的能量变得非常大。
>
> **信息压缩**：在信息理论中，将一个数据流压缩到较低熵的状态相对容易，但进一步压缩到极限会变得越来越困难，需要更多的计算资源和能量投入。

 但Decoder-only的模型结构决定了这个能量消耗的增长与序列长度是线性的关系。这一点就与物理规律不太相符了。一般熵越低，维持或进一步降低熵需要的能量就越多，这个能量需求的增长一般不是线性增长的。

> **绝对零度附近的系统**：在热力学中，接近绝对零度时，熵已经非常低，进一步降低熵的能量需求会变得极其高，这通常表现为非线性的能量需求增长。
>
> **信息压缩**：在信息压缩中，最初的压缩可能较为容易，但要将信息进一步压缩到接近其熵极限（即无损压缩的极限），需要付出越来越多的计算资源和能量，这通常也是非线性增长的。
>
> **物质的相变过程**：在某些相变过程中，熵的变化与能量输入之间的关系可能表现出复杂的非线性行为。尤其在临界点附近，系统对能量的响应可能变得非常复杂。

 通过回退的方式, 消耗更多算力(能量), 得到更稳定的熵减.