## 模型

以分类为例, 输入空间$\mathcal X$和输出空间$\mathcal Y$构成了一个样本空间. 对于空间中的样本$(x,y)\in\mathcal X \times \mathcal Y$, 假定$x$和$y$之间的关系可以通过一个未知的<u>真实条件概率分布</u>$p_r(y|x)$来描述. 机器学习的目标就是用一个<u>模型</u>$f(x; \theta)$来近似这个真实条件概率分布.

## 数据集

**1. 为什么要求数据是独立同分布(Identically and Independently Distributed, IID)的?**

独立同分布: 即独立地从某一个分布中抽取, 即每个样本$(x, y)$是从$\mathcal X$和$\mathcal Y$的联合空间中按照某个未知分布$p_r(x, y)$独立地随机产生的.

本质上都是为了保证被学习的分布是真实分布. 学习目标就是拟合未知的真实条件概率分布$p_r(y|x)$, 如果数据中包含来自其他分布的数据或数据不是独立采样的, 都会导致模型学到偏移的分布.

## 损失

一个好的模型$f(x, \theta^*)$, 应该在任意的的$(x,y)\in\mathcal X \times \mathcal Y$上都与真实条件概率分布$p_r(y|x)$一致, 即:
$$
|f(x, \theta^*)-p_r(y|x)|<\epsilon
$$
因此模型的好坏可以用<u>期望风险(Expected Risk)</u>$R(\theta)$来衡量:
$$
\mathcal R(\theta)=\mathbb E_{(x, y)\sim p_r(x, y)}[\mathcal L(y, f(x;\theta))]
$$
其中$p_r(x, y)$是真实数据分布, $\mathcal L(y, f(x;\theta))$为损失函数, 其用来量化两个变量之间的差异. 一般用<u>交叉熵</u>或<u>KL散度</u>来衡量两个分布之间的差异.

## 优化

现在, 我们可以说一个好的模型应当有一个较小的<u>期望风险$\mathcal R(\theta)$.</u> 但因为我们不知道真实的数据分布$p_r(x, y)$(知道的话还要模型近似干嘛), 所以也就无法计算这个值. 但对于给定的数据集$\mathcal D=\set{x_i, y_i}_{n=1}^N$, 我们可以计算<u>经验风险(Empirical Risk)</u>, 即在$\mathcal D$上的平均损失:
$$
\mathcal R_\mathcal D^{emp}(\theta) = \frac 1 N \sum_{i=1}^N{\mathcal L (y_i, f(x_i, \theta))}
$$
因此, 一个切实的优化准则就是找到一组参数$\theta ^*$使经验风险最小:
$$
\theta ^*= \mathop{\arg\min}\limits_{\theta}\ \mathcal R_\mathcal D^{emp}(\theta)
$$

这就是<u>经验风险最小化(Empirical Risk Minimization, ERM)</u>.

> **过拟合**
>
> 根据大数定理可知，当训练集大小$|\mathcal D|$​趋向于无穷大时，经验风险就趋向于期望风险．==然而通常情况下，我们无法获取无限的训练样本. 训练样本往往是真实数据的一个很小的子集或者包含一定的噪声数据，不能很好地反映全部数据的真实分布．==
>
> 经验风险最小化原则很容易导致模型在训练集上错误率很低，但是在未知数据上错误率很高．这就是所谓的<u>过拟合(Overfitting)</u>．

过拟合问题往往是由于训练数据少和噪声以及模型能力强等原因造成的. 为了解决过拟合问题，一般在经验风险最小化的基础上再引入参数的正则化（Regularization）来限制模型能力，使其不要过度地最小化经验风险. 这种准则就是<u>结构风险最小化(Structure Risk Minimization，SRM)</u>：
$$
\theta ^*= \mathop{\arg\min}\limits_{\theta}\ \mathcal R_\mathcal D^{emp}(\theta)+\frac 1 2 \lambda \vert\vert \theta \vert\vert^2
$$
其中$\vert\vert \theta \vert\vert$是$\mathcal l_2$范数的<u>正则化项</u>, 用来减少参数空间从而避免过拟合, $\lambda$用来控制正则化的强度.

> **欠拟合**
>
> 和过拟合相反的一个概念是<u>欠拟合(Underfitting)</u>，即模型不能很好地拟合训练数据，在训练集上的错误率比较高．==欠拟合一般是由于模型能力不足造成的==．

> **交叉熵损失和最大似然估计**
>
> 概率与似然: 概率，用于在已知一些参数的情况下，预测接下来在观测上所得到的结果；似然性，则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值，也就是说已观察到某事件后，对相关参数进行猜测。
>
> 当真实条件概率分布$p_r(y|x)$是one-hot向量时, <u>交叉熵损失函数</u>等价于<u>负对数似然函数</u>, 最小化交叉熵损失等价于最大化似然函数
>
> -  似然函数: 
>    $$
>    \begin{align}
>    L(\theta) &= \prod_{i=1}^{n} P_\theta(\left( x_{i}, y_i\right))\\
>    &=\prod_{i=1}^n{P_\theta(y_i|x_i)P(x_i)}\\
>    &=\prod_{i=1}^n{P(x_i)}\prod_{i=1}^n{f_{y_i}(x_i, \theta)}\\
>    \log L(\theta) &=C\sum_{i=1}^n{\log{f_{y_i}(x_i, \theta)}}
>    \end{align}
>    $$
>     其中$f_{y_i}(x_i, \theta)$表示模型预测分布$f(x_i;\theta)$中, $y=y_i$对应的概率. $\log \prod_{i=1}^n{P(x_i)}$与参数无关, 可以视作一个常数$C>0$.
>
> - 交叉熵损失: 
>    $$
>    \begin{align}
>    \text{CELoss}(\theta)&=-\sum_{i=1}^n{\sum_{j=1}^c p_r(y_j|x_i)\log{f_{y_j}(x_i, \theta)}}\\
>    &=-\sum_{i=1}^n{\log{f_{y_i}(x_i, \theta)}}\\
>    \end{align}
>    $$
>    其中$c$代表种类数.  简化是因为当且仅当$y_j=y_i$时, $p_r(y_j|x_i)\neq0$.
>
> 显然, 交叉熵损失函数与似然函数之间只差一个$-C$, 最小化交叉熵损失等价于最大化似然函数.
